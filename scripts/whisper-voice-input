#!/usr/bin/env python3
"""
Whisper Voice Input Script
Records audio and transcribes it using OpenAI Whisper API or local Whisper server
Then types the recognized text into the active window
"""

import os
import sys
import tempfile
import subprocess
import json
import signal
from pathlib import Path

try:
    import requests
except ImportError:
    print("ERROR: python3-requests is not installed", file=sys.stderr)
    sys.exit(1)


# Exit codes
EXIT_SUCCESS = 0
EXIT_CONFIG_ERROR = 1
EXIT_RECORDING_ERROR = 2
EXIT_TRANSCRIPTION_ERROR = 3
EXIT_CANCELLED = 4
EXIT_TIMEOUT = 5


def record_audio_user_controlled(max_duration=300, output_file="/tmp/voice-input.wav"):
    """
    Record audio using ffmpeg until SIGTERM is received or max duration reached.
    Returns tuple: (success: bool, reached_max: bool)
    """
    ffmpeg_process = None

    def signal_handler(signum, frame):
        # User stopped recording - kill ffmpeg and continue
        if ffmpeg_process:
            ffmpeg_process.terminate()
        raise InterruptedError("Recording stopped by user")

    # Set up signal handler for SIGTERM
    signal.signal(signal.SIGTERM, signal_handler)

    try:
        # Use PulseAudio default source with maximum duration
        cmd = [
            'ffmpeg',
            '-f', 'pulse',
            '-i', 'default',
            '-t', str(max_duration),
            '-acodec', 'pcm_s16le',
            '-ar', '16000',
            '-ac', '1',
            '-y',  # Overwrite output file
            output_file
        ]

        print(f"Recording (max {max_duration} seconds)...", file=sys.stderr)
        ffmpeg_process = subprocess.Popen(
            cmd,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=True
        )

        # Wait for ffmpeg to complete or be terminated
        returncode = ffmpeg_process.wait()

        # Check if ffmpeg completed naturally (reached max duration)
        if returncode == 0:
            # Check file size to determine if we actually recorded something
            if os.path.exists(output_file) and os.path.getsize(output_file) > 0:
                print(f"Recording reached maximum duration ({max_duration}s)", file=sys.stderr)
                return (True, True)  # Success, reached max
            else:
                print("ERROR: No audio recorded", file=sys.stderr)
                return (False, False)
        else:
            print(f"ERROR: ffmpeg failed with code {returncode}", file=sys.stderr)
            return (False, False)

    except InterruptedError:
        # User stopped recording via SIGTERM - this is normal
        # Wait for ffmpeg to finish writing
        if ffmpeg_process:
            try:
                ffmpeg_process.wait(timeout=2)
            except subprocess.TimeoutExpired:
                ffmpeg_process.kill()

        # Check if file was created and has content
        if os.path.exists(output_file) and os.path.getsize(output_file) > 0:
            print("Recording stopped by user", file=sys.stderr)
            return (True, False)  # Success, user stopped
        else:
            print("ERROR: No audio recorded", file=sys.stderr)
            return (False, False)

    except Exception as e:
        print(f"ERROR: Recording failed: {e}", file=sys.stderr)
        if ffmpeg_process:
            try:
                ffmpeg_process.kill()
            except:
                pass
        return (False, False)


def transcribe_openai(audio_file, api_key, language="auto", model="whisper-1"):
    """
    Transcribe audio using OpenAI Whisper API
    """
    if not api_key:
        print("ERROR: OPENAI_API_KEY is not set", file=sys.stderr)
        return None

    try:
        url = "https://api.openai.com/v1/audio/transcriptions"
        headers = {
            "Authorization": f"Bearer {api_key}"
        }

        with open(audio_file, 'rb') as f:
            files = {
                'file': (os.path.basename(audio_file), f, 'audio/wav'),
                'model': (None, model)
            }

            if language != "auto":
                files['language'] = (None, language)

            print(f"Sending to OpenAI {model} API...", file=sys.stderr)
            response = requests.post(url, headers=headers, files=files, timeout=30)

        if response.status_code == 200:
            result = response.json()
            return result.get('text', '').strip()
        else:
            print(f"ERROR: OpenAI API error: {response.status_code} {response.text}", file=sys.stderr)
            return None

    except Exception as e:
        print(f"ERROR: OpenAI transcription failed: {e}", file=sys.stderr)
        return None


def transcribe_gpt4o_audio(audio_file, api_key, language="auto"):
    """
    Transcribe audio using OpenAI GPT-4o Audio model
    This model provides better context understanding and emotion detection
    """
    if not api_key:
        print("ERROR: OPENAI_API_KEY is not set", file=sys.stderr)
        return None

    try:
        import base64

        url = "https://api.openai.com/v1/chat/completions"
        headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json"
        }

        # Read and encode audio file to base64
        with open(audio_file, 'rb') as f:
            audio_data = f.read()
            audio_base64 = base64.b64encode(audio_data).decode('utf-8')

        # Prepare prompt based on language
        if language == "auto":
            prompt = "Transcribe this audio to text. Detect the language automatically."
        else:
            language_names = {
                'ru': 'Russian',
                'en': 'English',
                'es': 'Spanish',
                'de': 'German',
                'fr': 'French',
                'zh': 'Chinese',
                'ja': 'Japanese'
            }
            lang_name = language_names.get(language, language)
            prompt = f"Transcribe this audio to text in {lang_name}."

        data = {
            "model": "gpt-4o-audio-preview",
            "modalities": ["text"],
            "messages": [
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "input_audio",
                            "input_audio": {
                                "data": audio_base64,
                                "format": "wav"
                            }
                        },
                        {
                            "type": "text",
                            "text": prompt
                        }
                    ]
                }
            ]
        }

        print("Sending to OpenAI GPT-4o Audio API...", file=sys.stderr)
        response = requests.post(url, headers=headers, json=data, timeout=60)

        if response.status_code == 200:
            result = response.json()
            # Extract text from chat completion response
            if 'choices' in result and len(result['choices']) > 0:
                message = result['choices'][0].get('message', {})
                text = message.get('content', '').strip()
                return text
            else:
                print(f"ERROR: Unexpected response format: {result}", file=sys.stderr)
                return None
        else:
            print(f"ERROR: OpenAI API error: {response.status_code} {response.text}", file=sys.stderr)
            return None

    except Exception as e:
        print(f"ERROR: GPT-4o Audio transcription failed: {e}", file=sys.stderr)
        return None


def transcribe_local(audio_file, server_url, language="auto"):
    """
    Transcribe audio using local Whisper server (e.g., faster-whisper-server)
    """
    try:
        with open(audio_file, 'rb') as f:
            files = {
                'audio_file': (os.path.basename(audio_file), f, 'audio/wav')
            }

            data = {}
            if language != "auto":
                data['language'] = language

            print(f"Sending to local Whisper server at {server_url}...", file=sys.stderr)
            response = requests.post(server_url, files=files, data=data, timeout=30)

        if response.status_code == 200:
            result = response.json()
            # Handle different response formats from various Whisper servers
            if 'text' in result:
                return result['text'].strip()
            elif 'transcription' in result:
                return result['transcription'].strip()
            elif 'results' in result and len(result['results']) > 0:
                return result['results'][0].get('transcript', '').strip()
            else:
                print(f"ERROR: Unexpected response format: {result}", file=sys.stderr)
                return None
        else:
            print(f"ERROR: Local server error: {response.status_code} {response.text}", file=sys.stderr)
            return None

    except requests.exceptions.ConnectionError:
        print(f"ERROR: Cannot connect to local Whisper server at {server_url}", file=sys.stderr)
        print("Make sure the server is running", file=sys.stderr)
        return None
    except Exception as e:
        print(f"ERROR: Local transcription failed: {e}", file=sys.stderr)
        return None


def get_active_window():
    """
    Get the active window ID using xdotool
    Returns window ID as string, or None on error
    """
    try:
        result = subprocess.run(
            ['xdotool', 'getactivewindow'],
            capture_output=True,
            text=True,
            timeout=2
        )

        if result.returncode == 0:
            return result.stdout.strip()
        else:
            print(f"ERROR: Failed to get active window: {result.stderr}", file=sys.stderr)
            return None

    except Exception as e:
        print(f"ERROR: Window tracking failed: {e}", file=sys.stderr)
        return None


def copy_to_clipboard(text):
    """
    Copy text to clipboard using xclip
    Returns True on success, False on failure
    """
    try:
        result = subprocess.run(
            ['xclip', '-selection', 'clipboard'],
            input=text.encode(),
            capture_output=True,
            timeout=5
        )

        if result.returncode == 0:
            return True
        else:
            print(f"ERROR: Failed to copy to clipboard: {result.stderr}", file=sys.stderr)
            return False

    except FileNotFoundError:
        print("ERROR: xclip is not installed", file=sys.stderr)
        return False
    except Exception as e:
        print(f"ERROR: Clipboard copy failed: {e}", file=sys.stderr)
        return False


def type_text(text):
    """
    Type text into the active window using xdotool - instant insertion
    Task 5.2: Remove character-by-character typing delays
    """
    if not text:
        return False

    try:
        # Task 5.2: Use single xdotool command for instant text insertion
        # Remove all delays - text should appear instantly
        result = subprocess.run(
            ['xdotool', 'type', '--', text],
            capture_output=True,
            text=True,
            timeout=10
        )

        if result.returncode != 0:
            print(f"ERROR: Failed to type text: {result.stderr}", file=sys.stderr)
            return False

        return True

    except Exception as e:
        print(f"ERROR: Typing failed: {e}", file=sys.stderr)
        return False


def main():
    # Get configuration from environment variables
    whisper_mode = os.environ.get('WHISPER_MODE', 'openai').lower()
    language = os.environ.get('WHISPER_LANGUAGE', 'auto')
    max_duration = int(os.environ.get('RECORDING_DURATION', '300'))
    openai_model = os.environ.get('OPENAI_MODEL', 'whisper-1')

    # Validate configuration
    if whisper_mode == 'openai':
        api_key = os.environ.get('OPENAI_API_KEY', '')
        if not api_key:
            print("ERROR: OPENAI_API_KEY is not set", file=sys.stderr)
            sys.exit(EXIT_CONFIG_ERROR)
    elif whisper_mode == 'local':
        server_url = os.environ.get('WHISPER_LOCAL_URL', '')
        if not server_url:
            print("ERROR: WHISPER_LOCAL_URL is not set", file=sys.stderr)
            sys.exit(EXIT_CONFIG_ERROR)
    else:
        print(f"ERROR: Unknown WHISPER_MODE: {whisper_mode}", file=sys.stderr)
        sys.exit(EXIT_CONFIG_ERROR)

    # Task 5.3: Capture initial active window ID
    initial_window_id = get_active_window()
    if not initial_window_id:
        print("WARNING: Could not get initial window ID, window tracking disabled", file=sys.stderr)

    # Create temporary file for audio
    temp_audio = tempfile.mktemp(suffix='.wav', prefix='whisper-voice-')

    try:
        # Task 5.5: Record audio with user control and maximum duration
        success, reached_max = record_audio_user_controlled(max_duration, temp_audio)

        if not success:
            sys.exit(EXIT_RECORDING_ERROR)

        # Task 5.6: Exit with code 5 if maximum duration reached
        if reached_max:
            # Still transcribe the audio, but will notify applet
            print("Maximum recording duration reached", file=sys.stderr)

        # Step 2: Transcribe
        text = None

        if whisper_mode == 'openai':
            api_key = os.environ.get('OPENAI_API_KEY', '')

            # Route to appropriate transcription function based on model
            if openai_model == 'gpt-4o-audio-preview':
                text = transcribe_gpt4o_audio(temp_audio, api_key, language)
            else:
                # Default to whisper-1 or other whisper models
                text = transcribe_openai(temp_audio, api_key, language, openai_model)

        elif whisper_mode == 'local':
            server_url = os.environ.get('WHISPER_LOCAL_URL', 'http://localhost:9000/asr')
            text = transcribe_local(temp_audio, server_url, language)

        if not text:
            print("No text recognized", file=sys.stderr)
            sys.exit(EXIT_TRANSCRIPTION_ERROR)

        # Step 3: Check if active window changed
        print(f"Recognized: {text}", file=sys.stderr)

        # Task 5.3 & 5.4: Check for window change
        if initial_window_id:
            current_window_id = get_active_window()

            if current_window_id and current_window_id != initial_window_id:
                # Window changed - copy to clipboard and notify
                print("WINDOW_CHANGED", file=sys.stdout)
                print(text, file=sys.stdout)

                if copy_to_clipboard(text):
                    print("Text copied to clipboard", file=sys.stderr)
                else:
                    print("WARNING: Failed to copy to clipboard", file=sys.stderr)

                # Exit with success but different behavior
                if reached_max:
                    sys.exit(EXIT_TIMEOUT)
                else:
                    sys.exit(EXIT_SUCCESS)

        # Window didn't change - type text normally
        if type_text(text):
            # Output the recognized text to stdout (for the applet)
            print(text, file=sys.stdout)

            if reached_max:
                sys.exit(EXIT_TIMEOUT)
            else:
                sys.exit(EXIT_SUCCESS)
        else:
            sys.exit(EXIT_TRANSCRIPTION_ERROR)

    finally:
        # Cleanup temporary file
        if os.path.exists(temp_audio):
            try:
                os.remove(temp_audio)
            except:
                pass


if __name__ == '__main__':
    main()
